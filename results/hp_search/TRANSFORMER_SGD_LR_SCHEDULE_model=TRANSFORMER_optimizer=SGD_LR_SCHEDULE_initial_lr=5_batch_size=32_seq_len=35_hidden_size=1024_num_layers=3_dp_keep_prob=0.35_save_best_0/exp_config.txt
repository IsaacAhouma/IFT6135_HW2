batch_size    32
code_file    ptb-lm.py
data    data
debug    False
dp_keep_prob    0.35
emb_size    200
evaluate    False
hidden_size    1024
initial_lr    5.0
load_weights    None
model    TRANSFORMER
num_epochs    40
num_layers    3
optimizer    SGD_LR_SCHEDULE
save_best    True
save_dir    TRANSFORMER_SGD_LR_SCHEDULE_model=TRANSFORMER_optimizer=SGD_LR_SCHEDULE_initial_lr=5_batch_size=32_seq_len=35_hidden_size=1024_num_layers=3_dp_keep_prob=0.35_save_best_0
seed    1111
seq_len    35
